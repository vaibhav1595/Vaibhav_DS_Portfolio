<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects on Vaibhav Panchal</title>
    <link>https://vaibhav1595.github.io/Vaibhav_Portfolio/post/</link>
    <description>Recent content in Projects on Vaibhav Panchal</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 02 Apr 2020 12:00:00 -0500</lastBuildDate>
    
	<atom:link href="https://vaibhav1595.github.io/Vaibhav_Portfolio/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Bioinformatics Project: Computational Drug Discovery</title>
      <link>https://vaibhav1595.github.io/Vaibhav_Portfolio/post/project-14-bioinformatics-project-computational-drug-discovery/</link>
      <pubDate>Tue, 02 Jun 2020 10:58:08 -0400</pubDate>
      
      <guid>https://vaibhav1595.github.io/Vaibhav_Portfolio/post/project-14-bioinformatics-project-computational-drug-discovery/</guid>
      <description>Ongoing Project&amp;hellip; Link to GitHub Repository</description>
    </item>
    
    <item>
      <title>Sentiment Analysis of Stocks from Financial News in Finviz website</title>
      <link>https://vaibhav1595.github.io/Vaibhav_Portfolio/post/project-12-extract-stock-sentiment-from-news-headlines/</link>
      <pubDate>Thu, 28 May 2020 10:58:08 -0400</pubDate>
      
      <guid>https://vaibhav1595.github.io/Vaibhav_Portfolio/post/project-12-extract-stock-sentiment-from-news-headlines/</guid>
      <description>Feel free to visit FinViz website for fundamental ratios, technical indicators to news headlines and insider training data, it is a perfect stock screener. Furthermore, it has updated information on the performance of each sector, industry and any major stock index.
 Loaded the saved HTML files by identifying the folder path and directing BeautifulSoup to ‘read’ the table of headlines Parsed the scraped text into data and time, and Organized the data for Visualization and Analysis Implemented NLTK VADER for Sentiment Analysis, and Customized the Sentiment Scoring System Merged Sentiment scores and Headlines Data, and removed the duplicates to visualize the results Performed and Visualized the Sentiment on one single trading day for Facebook Stock  Tesla:     Facebook:   Link to GitHub Repository</description>
    </item>
    
    <item>
      <title>Distinguish between a honey bee and a bumble bee using Deep Learning</title>
      <link>https://vaibhav1595.github.io/Vaibhav_Portfolio/post/project-11-distinguish-between-a-honey-bee-and-a-bumble-bee-using-deep-learning/</link>
      <pubDate>Tue, 26 May 2020 10:58:08 -0400</pubDate>
      
      <guid>https://vaibhav1595.github.io/Vaibhav_Portfolio/post/project-11-distinguish-between-a-honey-bee-and-a-bumble-bee-using-deep-learning/</guid>
      <description>This project is a series of projects that walk through working with image data, building classifiers using traditional techniques, and leveraging the power of deep learning for computer vision.
  Image Loading and Processing - This project is the FIRST part of a series of projects, in this I will use the Python image library Pillow to load and manipulate image data.
  Predict Species from Images - This project is the SECOND part of a series of projects, in this I will then build a model to identify honey bees and bumble bees given an image of these insects.</description>
    </item>
    
    <item>
      <title>Predicting Blood Donation</title>
      <link>https://vaibhav1595.github.io/Vaibhav_Portfolio/post/project-13-predicting-blood-donation/</link>
      <pubDate>Mon, 25 May 2020 10:58:08 -0400</pubDate>
      
      <guid>https://vaibhav1595.github.io/Vaibhav_Portfolio/post/project-13-predicting-blood-donation/</guid>
      <description>Checked Target Incidence using a Binary classifier Model which provides the output in &amp;lsquo;0 - the donor will not give blood&amp;rsquo; and &amp;lsquo;1 - the donor will give blood&amp;rsquo;. Result is [&amp;lsquo;0&amp;rsquo; - 0.762] &amp;amp; [&amp;lsquo;1&amp;rsquo; - 0.238] Zeroed into LogisticRegression model using TPOT, a Python Automated Machine Learning tool that optimizes machine learning pipelines using genetic programming, giving us the AUC score of 0.7850 Improved the AUC score by 0.</description>
    </item>
    
    <item>
      <title>Risk and Returns: The Sharpe Ratio</title>
      <link>https://vaibhav1595.github.io/Vaibhav_Portfolio/post/project-9-risk-and-rewards-the-sharpe-ratio/</link>
      <pubDate>Sat, 23 May 2020 10:58:08 -0400</pubDate>
      
      <guid>https://vaibhav1595.github.io/Vaibhav_Portfolio/post/project-9-risk-and-rewards-the-sharpe-ratio/</guid>
      <description>Loaded, Visualized, and summarized daily stock price data for &amp;lsquo;Amazon&amp;rsquo;, &amp;lsquo;Facebook&amp;rsquo; and &amp;lsquo;S&amp;amp;P500&amp;rsquo; Calculated daily stock returns data for &amp;lsquo;Amazon&amp;rsquo;, &amp;lsquo;Facebook&amp;rsquo; and &amp;lsquo;S&amp;amp;P500&amp;rsquo; Performed calculations for &amp;lsquo;Excess Returns: S&amp;amp;P 500 VS Stocks&amp;rsquo; Computed &amp;lsquo;Mean&amp;rsquo; and &amp;lsquo;Standard Deviations&amp;rsquo; for Excess Returns Determined &amp;lsquo;Sharpe Ratio&amp;rsquo; to help understand the return of an investment compared to its risk  Link to GitHub Repository</description>
    </item>
    
    <item>
      <title>Who&#39;s Tweeting - Trump or Trudeau ?</title>
      <link>https://vaibhav1595.github.io/Vaibhav_Portfolio/post/project-10-whos-tweeting-trump-or-trudeau/</link>
      <pubDate>Sat, 23 May 2020 10:58:08 -0400</pubDate>
      
      <guid>https://vaibhav1595.github.io/Vaibhav_Portfolio/post/project-10-whos-tweeting-trump-or-trudeau/</guid>
      <description>Loaded corpus of tweets from November 2017 into Pandas DataFrame, and passed it to scikit-learn for further processing Created vectorized representations of the tweets using &amp;lsquo;CountVectorizer&amp;rsquo; and &amp;lsquo;TfidfVectorizer&amp;rsquo; classes in order to apply machine learning after splitting the data into test and training sets Trained Multinomial Naive Bayes model with both the CountVectorizer and TfidfVectorizer data to check which model will perform better. Results are TF-IDF model performs better with 0.</description>
    </item>
    
    <item>
      <title>Real-time Insights from Social Media Data</title>
      <link>https://vaibhav1595.github.io/Vaibhav_Portfolio/post/project-8-real-time-insights-from-social-media-data/</link>
      <pubDate>Fri, 22 May 2020 10:58:08 -0400</pubDate>
      
      <guid>https://vaibhav1595.github.io/Vaibhav_Portfolio/post/project-8-real-time-insights-from-social-media-data/</guid>
      <description>Loaded and inspected data for topics that were hot worldwide (WW) and in the United States (US) at the moment of query Used json.dumps() method to have the data formatted as a pretty JSON string Used python&amp;rsquo;s set datastructure to find the common trends between &amp;ldquo;World Trends&amp;rdquo; and &amp;ldquo;US Trends&amp;rdquo; Digged deeper to explore the common hot trend &amp;ldquo;#WeLoveTheEarth&amp;rdquo; Performed frequency analysis to get the sense of the data and Extracted useful information from retweets Manipulated and Visualized the data in a better and richer way Analysed languages used in tweets  Link to GitHub Repository</description>
    </item>
    
    <item>
      <title>Uncovering The Hottest Topics in Machine Learning</title>
      <link>https://vaibhav1595.github.io/Vaibhav_Portfolio/post/project-5-uncovering-the-hottest-topics-in-machine-learning/</link>
      <pubDate>Tue, 19 May 2020 10:58:08 -0400</pubDate>
      
      <guid>https://vaibhav1595.github.io/Vaibhav_Portfolio/post/project-5-uncovering-the-hottest-topics-in-machine-learning/</guid>
      <description>Explored the NIPS Papers data, to determine what type of data it is and how it is structured Prepared the data by removing all the columns that do not contain useful text information Visualized the number of publications per year, to understand the extent of the machine learning &amp;lsquo;revolution&amp;rsquo;! Modified the text data by applying regular expression to remove any punctuation in the title to make it more amenable for analysis Created a word cloud of the titles of the research papers using Andreas Mueller’s word cloud library.</description>
    </item>
    
    <item>
      <title>Book Recommendations from Charles Darwin</title>
      <link>https://vaibhav1595.github.io/Vaibhav_Portfolio/post/project-7-book-recommendations-from-charles-darwin/</link>
      <pubDate>Mon, 18 May 2020 10:58:08 -0400</pubDate>
      
      <guid>https://vaibhav1595.github.io/Vaibhav_Portfolio/post/project-7-book-recommendations-from-charles-darwin/</guid>
      <description>Explored the books to be used in recommendation system, and loaded the contents of each book Pre-processed the data to facilitate the downstream analysis Referred Darwin&amp;rsquo;s most famous book: &amp;ldquo;On the Origin of Species.&amp;rdquo; for consistency of the analysis Transformed the Corpus (collection of words) into a format that is easier to deal with for the downstream analyses, i.e., transform each text into a list of the individual words (called tokens) Implemented Stemming Process to group together the inflected forms of a word so they can be analyzed as a single item: the stem Loaded the final result from a pickle file to make the process faster, as stemming algorithm takes several minutes to run Created universe of all words, i.</description>
    </item>
    
    <item>
      <title>Predicting Credit Card Approvals</title>
      <link>https://vaibhav1595.github.io/Vaibhav_Portfolio/post/project-6-predicting-credit-card-approvals/</link>
      <pubDate>Sun, 17 May 2020 10:58:08 -0400</pubDate>
      
      <guid>https://vaibhav1595.github.io/Vaibhav_Portfolio/post/project-6-predicting-credit-card-approvals/</guid>
      <description>Loaded and Viewed the confidential dataset, as the contributor of the dataset has anonymized the feature names Read this blog, to better understand the anonymized features Handled all missing values, as they affect the performance of machine learning model if they go unchanged Preprocessed the data into Three main tasks: Converted the non-numeric data into numeric, Splitting the data into train and test sets, and Scaled the feature values to a uniform range Fitted a Logistic Regression model (a generalized linear model), and Evaluated the model on the test set with respect to classification accuracy, and summarized the performance of a classification algorithm using Confusion matrix Performed GridSearchCV by defining the grid of values to two hyperparameters &amp;lsquo;tol&amp;rsquo; and &amp;lsquo;max_iter&amp;rsquo; to improve the model&amp;rsquo;s ability to predict credit card approvals Summarized the best achieved model score of 85% and the respective best parameters  Link to GitHub Repository</description>
    </item>
    
    <item>
      <title>Predict Data Science Salary</title>
      <link>https://vaibhav1595.github.io/Vaibhav_Portfolio/post/project-1-predict-data-science-salary/</link>
      <pubDate>Sun, 19 Apr 2020 10:58:08 -0400</pubDate>
      
      <guid>https://vaibhav1595.github.io/Vaibhav_Portfolio/post/project-1-predict-data-science-salary/</guid>
      <description>Developed a tool estimating the salary for the position of data science job with (MAE) ~ $13k posted on glassdoor.com in the United States Scraped 1000 Jobs lists from Glassdoor using python and selenium Performed Exploratory Data Analysis to uncover the underlying important structure of the Glassdoor job dataset Engineered features from the text of each job description to quantify the value companies put on Python, SQL, R, Spark, AWS and Excel Optimized Linear, Lasso, and Random Forest Regressors using GridsearchCV to reach the best model Created a client facing API using flask  Link to GitHub Repository</description>
    </item>
    
    <item>
      <title>Sentiment Analysis on Latest Avengers Movies with Tweets</title>
      <link>https://vaibhav1595.github.io/Vaibhav_Portfolio/post/project-2-sentiment-analysis-on-latest-avengers-movies-with-tweets/</link>
      <pubDate>Fri, 10 Apr 2020 10:58:08 -0400</pubDate>
      
      <guid>https://vaibhav1595.github.io/Vaibhav_Portfolio/post/project-2-sentiment-analysis-on-latest-avengers-movies-with-tweets/</guid>
      <description>Scraped twitter tweets using Twitter Scraper Successfully applied VADER sentimental analysis tool to get peoples sentiments Applied Langdetect to extract English (‘en’) language tweets Compared Avengers: Endgame 2019 movie sentiments to previous year Avengers: Infinity war movie  Link to GitHub Repository</description>
    </item>
    
    <item>
      <title>Predict Admit chance to Graduate Programs.</title>
      <link>https://vaibhav1595.github.io/Vaibhav_Portfolio/post/project-3-predict-admit-chance-to-graduate-programs/</link>
      <pubDate>Sat, 04 Apr 2020 10:58:08 -0400</pubDate>
      
      <guid>https://vaibhav1595.github.io/Vaibhav_Portfolio/post/project-3-predict-admit-chance-to-graduate-programs/</guid>
      <description>Performed Exploratory Data Analysis to find correlation and distribution of various parameters Applied Linear Regression Machine Learning Model to predict the target variable ‘Chance of Admit’ Identified most crucial parameter for ‘High Chance of Admit’ by applying Feature Importance using Random Forest Regressor  Link to GitHub Repository</description>
    </item>
    
    <item>
      <title>Forecast Medical Insurance Cost</title>
      <link>https://vaibhav1595.github.io/Vaibhav_Portfolio/post/project-4-forecast-medical-insurance-cost/</link>
      <pubDate>Fri, 03 Apr 2020 10:58:08 -0400</pubDate>
      
      <guid>https://vaibhav1595.github.io/Vaibhav_Portfolio/post/project-4-forecast-medical-insurance-cost/</guid>
      <description>Cleaned the data and conducted Exploratory Data Analysis Transformed hashable and comparable non-numerical labels to numerical labels using LabelEncoder Applied Polynomial and Linear Regression Machine Learning Models to predict the target variable ‘Insurance Cost’ accurately  Link to GitHub Repository</description>
    </item>
    
  </channel>
</rss>